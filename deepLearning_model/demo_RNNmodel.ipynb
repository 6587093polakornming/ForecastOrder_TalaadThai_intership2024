{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/time-series-forecasting-using-recurrent-neural-networks-rnn-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime(2020,4,1)\n",
    "end_date = dt.datetime(2023,4,1)\n",
    " \n",
    "#loading from yahoo finance\n",
    "data = yf.download(\"GOOGL\",start_date, end_date)\n",
    " \n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_columns',5)\n",
    "print(data)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting 80 percent data for training\n",
    "training_data_len = math.ceil(len(data) * .8)\n",
    " \n",
    "#Splitting the dataset\n",
    "train_data = data[:training_data_len].iloc[:,:1] \n",
    "test_data = data[training_data_len:].iloc[:,:1]\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape numpy array train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Open Price values\n",
    "dataset_train = train_data.Open.values \n",
    "# print(dataset_train)\n",
    "\n",
    "# Reshaping 1D to 2D array\n",
    "dataset_train = np.reshape(dataset_train, (-1,1)) \n",
    "dataset_train.shape\n",
    "# out1 = dataset_train[0]\n",
    "# out2 = dataset_train[0,0]\n",
    "# out3 = dataset_train[:10]\n",
    "# print(out3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# scaling dataset\n",
    "scaled_train = scaler.fit_transform(dataset_train)\n",
    " \n",
    "print(scaled_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape numpy array test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Open Price values\n",
    "dataset_test = test_data.Open.values \n",
    "# Reshaping 1D to 2D array\n",
    "dataset_test = np.reshape(dataset_test, (-1,1))  \n",
    "# Normalizing values between 0 and 1\n",
    "scaled_test = scaler.fit_transform(dataset_test)  \n",
    "print(*scaled_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set X, y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar to lags feature \n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(50, len(scaled_train)):\n",
    "    X_train.append(scaled_train[i-50:i, 0]) #lags feature 50 lags\n",
    "    y_train.append(scaled_train[i, 0])\n",
    "    if i <= 51:\n",
    "        print(X_train) #list\n",
    "        print(y_train)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(50, len(scaled_test)):\n",
    "    X_test.append(scaled_test[i-50:i, 0])\n",
    "    y_test.append(scaled_test[i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape X,y train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is converted to Numpy array\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    " \n",
    "#Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "y_train = np.reshape(y_train, (y_train.shape[0],1))\n",
    "print(\"X_train :\",X_train.shape,\"y_train :\",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, the data is converted into a format that is suitable for input to an RNN. np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1)) transforms the X_train array, which was originally a ***2-dimensional array of shape (samples, features), into a 3-dimensional array of shape (samples, time steps, features)***, where time steps denotes the number of time steps in the input sequence and features denotes the number of features in the input data. Size 1 is an additional dimension that serves as an indication that each time step only has a single feature.\n",
    "\n",
    "The y_train array is transformed from a 1-dimensional array of shape (samples) into a 2-dimensional array of shape (samples, 1) by np.reshape(y_train, (y_train.shape[0], 1)), where each row represents the output value at a certain time step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape X,y test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The data is converted to numpy array\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    " \n",
    "#Reshaping\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "y_test = np.reshape(y_test, (y_test.shape[0],1))\n",
    "print(\"X_test :\",X_test.shape,\"y_test :\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GRU, Bidirectional\n",
    "from keras.optimizers import SGD\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the RNN\n",
    "regressor = Sequential()\n",
    " \n",
    "# adding RNN layers and dropout regularization\n",
    "regressor.add(SimpleRNN(units = 50, \n",
    "                        activation = \"tanh\",\n",
    "                        return_sequences = True,\n",
    "                        input_shape = (X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    " \n",
    "regressor.add(SimpleRNN(units = 50, \n",
    "                        activation = \"tanh\",\n",
    "                        return_sequences = True))\n",
    " \n",
    "regressor.add(SimpleRNN(units = 50,\n",
    "                        activation = \"tanh\",\n",
    "                        return_sequences = True))\n",
    " \n",
    "regressor.add( SimpleRNN(units = 50))\n",
    " \n",
    "# adding the output layer\n",
    "regressor.add(Dense(units = 1,activation='sigmoid'))\n",
    " \n",
    "# compiling RNN\n",
    "regressor.compile(optimizer = SGD(learning_rate=0.01,\n",
    "                                  decay=1e-6, \n",
    "                                  momentum=0.9, \n",
    "                                  nesterov=True), \n",
    "                  loss = \"mean_squared_error\")\n",
    " \n",
    "# fitting the model\n",
    "regressor.fit(X_train, y_train, epochs = 20, batch_size = 2)\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model LSTM RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the model\n",
    "regressorLSTM = Sequential()\n",
    " \n",
    "#Adding LSTM layers\n",
    "regressorLSTM.add(LSTM(50, \n",
    "                       return_sequences = True, \n",
    "                       input_shape = (X_train.shape[1],1)))\n",
    "regressorLSTM.add(LSTM(50, \n",
    "                       return_sequences = False))\n",
    "regressorLSTM.add(Dense(25))\n",
    " \n",
    "#Adding the output layer\n",
    "regressorLSTM.add(Dense(1))\n",
    " \n",
    "#Compiling the model\n",
    "regressorLSTM.compile(optimizer = 'adam',\n",
    "                      loss = 'mean_squared_error',\n",
    "                      metrics = [\"accuracy\"])\n",
    " \n",
    "#Fitting the model\n",
    "regressorLSTM.fit(X_train, \n",
    "                  y_train, \n",
    "                  batch_size = 1, \n",
    "                  epochs = 12)\n",
    "regressorLSTM.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the model\n",
    "regressorGRU = Sequential()\n",
    " \n",
    "# GRU layers with Dropout regularisation\n",
    "regressorGRU.add(GRU(units=50, \n",
    "                     return_sequences=True,\n",
    "                     input_shape=(X_train.shape[1],1),\n",
    "                     activation='tanh'))\n",
    "regressorGRU.add(Dropout(0.2))\n",
    " \n",
    "regressorGRU.add(GRU(units=50, \n",
    "                     return_sequences=True,\n",
    "                     activation='tanh'))\n",
    " \n",
    "regressorGRU.add(GRU(units=50, \n",
    "                     return_sequences=True,\n",
    "                     activation='tanh'))\n",
    " \n",
    "regressorGRU.add(GRU(units=50, \n",
    "                     activation='tanh'))\n",
    " \n",
    "# The output layer\n",
    "regressorGRU.add(Dense(units=1,\n",
    "                       activation='relu'))\n",
    "# Compiling the RNN\n",
    "regressorGRU.compile(optimizer=SGD(learning_rate=0.01, \n",
    "                                   decay=1e-7, \n",
    "                                   momentum=0.9, \n",
    "                                   nesterov=False),\n",
    "                     loss='mean_squared_error')\n",
    " \n",
    "# Fitting the data\n",
    "regressorGRU.fit(X_train,y_train,epochs=20,batch_size=1)\n",
    "regressorGRU.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions with X_test data\n",
    "y_RNN = regressor.predict(X_test)\n",
    "y_LSTM = regressorLSTM.predict(X_test)\n",
    "y_GRU = regressorGRU.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling back from 0-1 to original\n",
    "y_RNN_O = scaler.inverse_transform(y_RNN) \n",
    "y_LSTM_O = scaler.inverse_transform(y_LSTM) \n",
    "y_GRU_O = scaler.inverse_transform(y_GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,figsize =(18,12),sharex=True, sharey=True)\n",
    "fig.suptitle('Model Predictions')\n",
    " \n",
    "#Plot for RNN predictions\n",
    "axs[0].plot(train_data.index[150:], train_data.Open[150:], label = \"train_data\", color = \"b\") # train_data\n",
    "axs[0].plot(test_data.index, test_data.Open, label = \"test_data\", color = \"g\") # test_data\n",
    "axs[0].plot(test_data.index[50:], y_RNN_O, label = \"y_RNN\", color = \"brown\") #y_RNN_O => y_test\n",
    "axs[0].legend()\n",
    "axs[0].title.set_text(\"Basic RNN\")\n",
    " \n",
    "#Plot for LSTM predictions\n",
    "axs[1].plot(train_data.index[150:], train_data.Open[150:], label = \"train_data\", color = \"b\")\n",
    "axs[1].plot(test_data.index, test_data.Open, label = \"test_data\", color = \"g\")\n",
    "axs[1].plot(test_data.index[50:], y_LSTM_O, label = \"y_LSTM\", color = \"orange\")\n",
    "axs[1].legend()\n",
    "axs[1].title.set_text(\"LSTM\")\n",
    " \n",
    "#Plot for GRU predictions\n",
    "axs[2].plot(train_data.index[150:], train_data.Open[150:], label = \"train_data\", color = \"b\")\n",
    "axs[2].plot(test_data.index, test_data.Open, label = \"test_data\", color = \"g\")\n",
    "axs[2].plot(test_data.index[50:], y_GRU_O, label = \"y_GRU\", color = \"red\")\n",
    "axs[2].legend()\n",
    "axs[2].title.set_text(\"GRU\")\n",
    " \n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Open price\")\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (mean_absolute_error,\n",
    "                             mean_squared_error,\n",
    "                             mean_absolute_percentage_error)\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "pred_dict = {\"RNN\":y_RNN_O,\"LSTM\":y_LSTM_O, \"GRU\":y_GRU_O}\n",
    "y_true = test_data[50:].Open\n",
    "print(y_true)\n",
    "\n",
    "for name, pred in pred_dict.items():\n",
    "    mae = mean_absolute_error(y_true, pred)\n",
    "    mse = mean_squared_error(y_true,pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    mape =mean_absolute_percentage_error(y_true,pred)\n",
    "    print(f\"==== {name} ====\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MSE {mse}\")\n",
    "    print(f\"RMSE {rmse}\")\n",
    "    print(f\"MAPE: {mape}\\n\")\n",
    "# print(RNN_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ...  # Get model (Sequential, Functional Model, or Model subclass)\n",
    "# model.save('path/to/location.keras')  # The file needs to end with the .keras extension\n",
    "# model = keras.models.load_model('path/to/location.keras')\n",
    "\n",
    "model = regressor.save('regressorRNN.keras')\n",
    "model = regressorLSTM.save('regressorLSTM.keras')\n",
    "model = regressorGRU.save('regressorGRU.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
